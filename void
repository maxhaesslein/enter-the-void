#!/usr/bin/python


# Enter the Void
# v1, 2023
# by maxhaesslein
# www.maxhaesslein.de

from queue import Queue
from threading import Thread
import numpy as np
import cv2
import pyaudio
import aubio
import sys
import time
import math

options = {
	'screenWidth': 1280,
	'screenHeight': 720,

	'fps': 30,

    'bufferSize': 512,
    'winSizeMultiple': 2, # 2 or 4

	'verbose': True,

	'windowName': 'Enter the Void',

    'audioDevice': 'auto',
    'audioDisplayScaling': 3000,

    'fpsSmoothing': 0.6, # this smoothes only the fps _debug display_, NOT the real fps

}

debugDisplay = {
    'frameCount': True,
    'fps': True,
    'audioFps': True,
    'bpm': True,
    'interval': True,
    'progress': True,
    'pitch': True,
    'volume': True,
    'peaks': True,
}


# setup window
cv2.namedWindow( options['windowName'], cv2.WINDOW_NORMAL )
cv2.resizeWindow( options['windowName'], options['screenWidth'], options['screenHeight'] )
cv2.setWindowProperty( options['windowName'], cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN )

# display startup image
startupImage = np.zeros((options['screenHeight'], options['screenWidth'], 3), np.uint8)
font = cv2.FONT_HERSHEY_TRIPLEX
text = 'loading ...'
fontSize = 1
fontWidth = 1
fontColor = (255,255,255)
textSize = cv2.getTextSize(text, font, fontSize, fontWidth)[0]
textX = int((options['screenWidth'] - textSize[0]) / 2)
textY = int((options['screenHeight'] - textSize[1]*2))
cv2.putText( img=startupImage, text=text, org=(textX, textY), fontFace=font, fontScale=fontSize, color=fontColor, thickness=fontWidth, lineType=cv2.LINE_AA )

cv2.imshow(options['windowName'], startupImage)
cv2.waitKey(60)

# get audio input options
pa = pyaudio.PyAudio()
if options['verbose']:
    print("listing microphones")
    for i in range(pa.get_device_count()):
        dev = pa.get_device_info_by_index(i)
        print(i,dev['name'],dev['maxInputChannels'])
        if options['audioDevice'] == 'auto' and dev['maxInputChannels'] > 0:
            options['audioDevice'] = i
            print('  automatically set audio device to '+str(i))
if pa.get_device_count() < options['audioDevice']:
    print('audio device index is out of range (found '+str(pa.get_device_count())+' audio devices, requested #'+str(options['audioDevice'])+')')
    sys.exit()
audioDevice = pa.get_device_info_by_index(options['audioDevice'])
if audioDevice['maxInputChannels'] <= 0:
    print('audio device has no input channels! aborting')
    print('(use "arecord -l" to check available devices)')
    sys.exit()
audioOptions = {
    'deviceIndex': audioDevice['index'],
    'sampleRate': int(audioDevice['defaultSampleRate']),
    'inputChannels': 1,
    'hopSize': options['bufferSize'],
    'winSize': options['bufferSize']*options['winSizeMultiple'],
}

if options['verbose']:
    print('')
    print('---------')
    print('')
    print('-- options --')
    print(options)
    print('')
    print('-- audio options --')
    print(audioOptions)
    print('')
    print('---------')
    print('')



class AudioProcessor():

    def __init__(self):

        self.fpsMeasurement = options['fps']
        self.previousTime = self.currentTime = time.time()
        self.fpsSmoothing = 0.9

        self.beatQueue = Queue()
        self.pitchQueue = Queue()

        peakBufferSize = int(audioOptions['sampleRate']/options['bufferSize']) # one second worth of bufferSizes
        self.peakBuffer = np.zeros(peakBufferSize)
        self.peakBufferBeat = np.zeros(peakBufferSize)
        self.peakBufferIndex = 0

        volumeBufferSize = int((audioOptions['sampleRate']/options['bufferSize'])/options['fps']) # one frame worth of bufferSizes
        if volumeBufferSize < 1:
            volumeBufferSize = 1
        self.volumeBuffer = np.zeros(volumeBufferSize)
        self.volumeBufferIndex = 0

        self.tempoDetection = aubio.tempo(method='default', buf_size=audioOptions['winSize'], hop_size=audioOptions['hopSize'], samplerate=audioOptions['sampleRate'])

        self.pitchDetection = aubio.pitch(method='default', buf_size=audioOptions['winSize'], hop_size=audioOptions['hopSize'], samplerate=audioOptions['sampleRate'])
        self.pitchDetection.set_unit('cent')

        self.audio = pyaudio.PyAudio()
        self.stream = self.audio.open(format=pyaudio.paFloat32,
                    input=True,
                    channels=audioOptions['inputChannels'],
                    input_device_index=audioOptions['deviceIndex'],
                    frames_per_buffer=options['bufferSize'],
                    rate=audioOptions['sampleRate'],
                    stream_callback=self.readAudioFrames)


    def readAudioFrames(self, in_data, frame_count, time_info, status):

        signal = np.frombuffer(in_data, dtype=np.float32)

        volume = np.sum(signal**2)/len(signal)

        beat = self.tempoDetection(signal)
        if beat:
            bpm = self.tempoDetection.get_bpm()
            self.beatQueue.put(bpm)

        pitch = self.pitchDetection(signal)
        if pitch[0] != 0:
            self.pitchQueue.put(pitch[0])

        peak = np.abs(np.max(signal)-np.min(signal))
        self.peakBuffer[self.peakBufferIndex] = peak*options['audioDisplayScaling']
        self.peakBufferBeat[self.peakBufferIndex] = beat

        self.peakBufferIndex += 1
        if self.peakBufferIndex >= len(self.peakBuffer):
            self.peakBufferIndex = 0

        self.volumeBuffer[self.volumeBufferIndex] = volume

        self.volumeBufferIndex += 1
        if self.volumeBufferIndex >= len(self.volumeBuffer):
            self.volumeBufferIndex = 0

        self.previousTime, self.currentTime = self.currentTime, time.time()
        fps = math.ceil(1./(self.currentTime-self.previousTime))
        self.fpsMeasurement = (self.fpsMeasurement*self.fpsSmoothing) + (fps*(1.0-self.fpsSmoothing))

        return (in_data, pyaudio.paContinue)

    def getBeat(self):
        if self.beatQueue.qsize() > 0:
            return self.beatQueue.get()
        return False

    def getPitch(self):
        if self.pitchQueue.qsize() > 0:
            return self.pitchQueue.get()
        return False

    def getPeaks(self):
        return self.peakBuffer, self.peakBufferBeat, self.peakBufferIndex

    def getVolume(self):
        volume = np.sum(self.volumeBuffer)
        return volume

    def getFps(self):
        return self.fpsMeasurement

    def stop(self):
        self.stream.stop_stream()
        self.stream.close()
        self.audio.terminate()


targetTime = 1./options['fps']
frameNumber = 0
bpm = -1
framesPerInterval = -1
framesUntilNextBeat = -1
lateBeat = False
pitchValue = 0
oldPitchValue = 0

volumeBuffer = np.zeros(options['fps']*10) # 10 seconds worth of frames
volumeBufferIndex = 0
globalVolume = 0
globalAverageVolume = 0
globalVolumeDisplaySmoothing = 0.7
volumePercentMeasurement = 1

fps = options['fps']
fpsDisplay = options['fps']
previousTime = time.time()
currentTime = time.time()

font = cv2.FONT_HERSHEY_TRIPLEX

audioProcessor = AudioProcessor()

# main loop
while True:

    startTime = time.time()

    stepTime = time.time()

    framesUntilNextBeat -= 1
    if framesUntilNextBeat < 0:
        lateBeat = True
        framesUntilNextBeat = 0

    beat = audioProcessor.getBeat()
    if beat:
        bpm = beat
        beat = True
        framesPerInterval = framesUntilNextBeat = fps*60/bpm
        lateBeat = False

    if pitchValue > 0:
        oldPitchValue = pitchValue
    pitchValue = 0
    pitch = audioProcessor.getPitch()
    if pitch and pitch > 0:
        pitchValue = pitch

    globalVolume = audioProcessor.getVolume()
    volumeBuffer[volumeBufferIndex] = globalVolume
    volumeBufferIndex += 1
    if volumeBufferIndex >= len(volumeBuffer):
        volumeBufferIndex = 0
    globalAverageVolume = np.sum(volumeBuffer)/len(volumeBuffer)

    step1Time = time.time()-stepTime
    stepTime = time.time()

    frame = np.zeros((options['screenHeight'], options['screenWidth'], 3), np.uint8)

    step2Time = time.time()-stepTime
    stepTime = time.time()

    # frame count debug text
    if debugDisplay['frameCount']:
        text = 'frame #'+str(frameNumber)+' / next beat at #'+str(int(frameNumber+framesUntilNextBeat))
        fontSize = 1
        fontWidth = 1
        fontColor = (255,255,255)
        textSize = cv2.getTextSize(text, font, fontSize, fontWidth)[0]
        textX = 1
        textY = options['screenHeight']-1
        cv2.putText( img=frame, text=text, org=(textX, textY), fontFace=font, fontScale=fontSize, color=fontColor, thickness=fontWidth, lineType=cv2.LINE_AA )

    step3Time = time.time()-stepTime
    stepTime = time.time()

    # fps debug text
    textY = 0
    if debugDisplay['fps']:
        text = str(math.ceil(fpsDisplay))+' main fps'
        fontSize = 1
        fontWidth = 1
        if fpsDisplay < options['fps']*0.8:
            fontColor = (0,0,255)
        elif fpsDisplay < options['fps']*0.9:
            fontColor = (0,255,255)
        else:
            fontColor = (0,255,0)
        textSize = cv2.getTextSize(text, font, fontSize, fontWidth)[0]
        textX = int((options['screenWidth'] - textSize[0]))
        textY = textSize[1]
        cv2.putText( img=frame, text=text, org=(textX, textY), fontFace=font, fontScale=fontSize, color=fontColor, thickness=fontWidth, lineType=cv2.LINE_AA )

    step4Time = time.time()-stepTime
    stepTime = time.time()

    # audioProcessor fps debug text
    if debugDisplay['audioFps']:
        audioFps = audioProcessor.getFps()
        text = str(math.ceil(audioFps))+' audio fps'
        fontSize = 1
        fontWidth = 1
        fontColor = (255,255,255)
        textSize = cv2.getTextSize(text, font, fontSize, fontWidth)[0]
        textX = int((options['screenWidth'] - textSize[0]))
        textY += textSize[1] + 20
        cv2.putText( img=frame, text=text, org=(textX, textY), fontFace=font, fontScale=fontSize, color=fontColor, thickness=fontWidth, lineType=cv2.LINE_AA )

    step5Time = time.time()-stepTime
    stepTime = time.time()

    # bpm debug text
    textY = int(options['screenHeight']/5)
    if debugDisplay['bpm']:
        text = str(round(bpm))+' bpm'
        fontSize = 1
        fontWidth = 1
        fontColor = (255,255,255)
        if beat:
            fontColor = (0,0,255)
        textSize = cv2.getTextSize(text, font, fontSize, fontWidth)[0]
        textX = int((options['screenWidth'] - textSize[0])/2)
        cv2.putText( img=frame, text=text, org=(textX, textY), fontFace=font, fontScale=fontSize, color=fontColor, thickness=fontWidth, lineType=cv2.LINE_AA )

    step6Time = time.time()-stepTime
    stepTime = time.time()

    # fpi debug text
    if debugDisplay['interval']:
        text = str(round(framesPerInterval))+' frames per interval'
        fontSize = 1
        fontWidth = 1
        fontColor = (255,255,255)
        if beat:
            fontColor = (0,0,255)
        textSize = cv2.getTextSize(text, font, fontSize, fontWidth)[0]
        textX = int((options['screenWidth'] - textSize[0])/2)
        textY += textSize[1]+20
        cv2.putText( img=frame, text=text, org=(textX, textY), fontFace=font, fontScale=fontSize, color=fontColor, thickness=fontWidth, lineType=cv2.LINE_AA )

    step7Time = time.time()-stepTime
    stepTime = time.time()


    # print progress bar until next beat
    y = int(options['screenHeight'] * 2/3)
    x = 300
    w = int(options['screenWidth'] - x*2)
    h = 30
    if debugDisplay['progress']:
        c = (255,255,255)
        if lateBeat:
            c = (0,0,255)
        lineWidth = 1
        filledWidth = round((1-(framesUntilNextBeat/framesPerInterval))*w)
        cv2.rectangle( frame, (x,y), (x+w, y+h), c, lineWidth )
        cv2.rectangle( frame, (x,y), (x+filledWidth, y+h), c, -1 )
        text = 'next beat'
        fontSize = 1
        fontWidth = 1
        fontColor = (255,255,255)
        textSize = cv2.getTextSize(text, font, fontSize, fontWidth)[0]
        cv2.putText( img=frame, text=text, org=(x-textSize[0]-10, int(y+h/2+textSize[1]/2)), fontFace=font, fontScale=fontSize, color=fontColor, thickness=fontWidth, lineType=cv2.LINE_AA )

    step8Time = time.time()-stepTime
    stepTime = time.time()

    # print pitch
    if debugDisplay['pitch']:
        y += h + 20
        c = (255,255,255)
        cOld = (50,50,50)
        lineWidth = 1
        filledWidth = int((pitchValue)*w/100)
        filledWidthOld = int((oldPitchValue)*w/100)
        cv2.rectangle( frame, (x,y), (x+filledWidthOld, y+h), cOld, -1 )
        cv2.rectangle( frame, (x,y), (x+filledWidth, y+h), c, -1 )
        cv2.rectangle( frame, (x,y), (x+w, y+h), c, lineWidth )
        text = 'pitch'
        fontSize = 1
        fontWidth = 1
        fontColor = (255,255,255)
        textSize = cv2.getTextSize(text, font, fontSize, fontWidth)[0]
        cv2.putText( img=frame, text=text, org=(x-textSize[0]-10, int(y+h/2+textSize[1]/2)), fontFace=font, fontScale=fontSize, color=fontColor, thickness=fontWidth, lineType=cv2.LINE_AA )

    step9Time = time.time()-stepTime
    stepTime = time.time()

    # print Volume
    if debugDisplay['volume']:
        y += h + 20
        c = (255,255,255)
        cB = (0,0,0)
        lineWidth = 1
        midW= int(w/2)
        scale = 4
        if globalAverageVolume > 0:
            volumePercent = globalVolume/globalAverageVolume
        else:
            volumePercent = 1
        if volumePercent > 2:
            volumePercent = 2
        volumePercentMeasurement = (volumePercentMeasurement*globalVolumeDisplaySmoothing) + (volumePercent * (1.0-globalVolumeDisplaySmoothing))
        filledWidth = midW*(volumePercentMeasurement-1)
        cv2.rectangle( frame, (x+midW,y), (x+midW+int(filledWidth), y+h), c, -1 )
        cv2.rectangle( frame, (x,y), (x+w, y+h), c, lineWidth )
        text = 'volume'
        fontSize = 1
        fontWidth = 1
        fontColor = (255,255,255)
        textSize = cv2.getTextSize(text, font, fontSize, fontWidth)[0]
        cv2.putText( img=frame, text=text, org=(x-textSize[0]-10, int(y+h/2+textSize[1]/2)), fontFace=font, fontScale=fontSize, color=fontColor, thickness=fontWidth, lineType=cv2.LINE_AA )

    step10Time = time.time()-stepTime
    stepTime = time.time()

    # print peaks
    if debugDisplay['peaks']:
        data, beatData, index = audioProcessor.getPeaks()
        index -= 1
        if index < 0:
            index = options['fps']-1

        w = math.ceil(options['screenWidth']/len(data))
        x = options['screenWidth']-w
        y = int(options['screenHeight']*3/5)

        for i in range(len(data)):
            h = int(data[index])
            o = beatData[index]

            color = (255,255,255)
            if o:
                color = (0,0,255)

            cv2.rectangle( frame, (x,y), (x+w, y-h), color, -1 )

            x += w

            index += 1
            if index >= len(data):
                index = 0
            if x >= options['screenWidth']:
                x = 0

    step11Time = time.time()-stepTime
    stepTime = time.time()


    cv2.imshow(options['windowName'], frame)

    step12Time = time.time()-stepTime
    stepTime = time.time()

    step1Time = '01: '+str(int(step1Time*100000))
    step2Time = '/ 02: '+str(int(step2Time*100000))
    step3Time = '/ 03: '+str(int(step3Time*100000))
    step4Time = '/ 04: '+str(int(step4Time*100000))
    step5Time = '/ 05: '+str(int(step5Time*100000))
    step6Time = '/ 06: '+str(int(step6Time*100000))
    step7Time = '/ 07: '+str(int(step7Time*100000))
    step8Time = '/ 08: '+str(int(step8Time*100000))
    step9Time = '/ 09: '+str(int(step9Time*100000))
    step10Time = '/ 10: '+str(int(step10Time*100000))
    step11Time = '/ 11: '+str(int(step11Time*100000))
    step12Time = '/ 12: '+str(int(step12Time*100000))

    print(step1Time, step2Time, step3Time, step4Time, step5Time, step6Time, step7Time, step8Time, step9Time, step10Time, step11Time, step12Time)

    frameNumber += 1

    previousTime, currentTime = currentTime, time.time()
    fps = round(1./(currentTime-previousTime))
    fpsDisplay = (fpsDisplay * options['fpsSmoothing']) + (fps * (1.0-options['fpsSmoothing']))


    usedTime = time.time() - startTime
    timeLeft = targetTime-usedTime
    sleepTime = int(timeLeft*1000)
    if sleepTime < 1:
        sleepTime = 1

    key = cv2.waitKey(sleepTime)

    if key == 27: # escape
        print('exiting')
        break
    elif key&0xFF == ord('q'):
        debugDisplay['frameCount'] = not debugDisplay['frameCount']
    elif key&0xFF == ord('w'):
        debugDisplay['fps'] = not debugDisplay['fps']
    elif key&0xFF == ord('e'):
        debugDisplay['audioFps'] = not debugDisplay['audioFps']
    elif key&0xFF == ord('r'):
        debugDisplay['bpm'] = not debugDisplay['bpm']
    elif key&0xFF == ord('t'):
        debugDisplay['interval'] = not debugDisplay['interval']
    elif key&0xFF == ord('z'):
        debugDisplay['progress'] = not debugDisplay['progress']
    elif key&0xFF == ord('u'):
        debugDisplay['pitch'] = not debugDisplay['pitch']
    elif key&0xFF == ord('i'):
        debugDisplay['volume'] = not debugDisplay['volume']
    elif key&0xFF == ord('o'):
        debugDisplay['peaks'] = not debugDisplay['peaks']


print('cleaning up ..')

audioProcessor.stop()
cv2.destroyAllWindows()

print('bye!')

