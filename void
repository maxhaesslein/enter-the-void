#!/usr/bin/python


# Enter the Void
# v1, 2023
# by maxhaesslein
# www.maxhaesslein.de

from queue import Queue
from threading import Thread
import numpy as np
import cv2
import pyaudio
import aubio
import sys
import time
import math

options = {
	'screenWidth': 1280,
	'screenHeight': 720,

	'fps': 30,

    'bufferSize': 512,
    'winSizeMultiple': 2, # 2 or 4

	'verbose': True,

	'windowName': 'Enter the Void',

    'audioDevice': 'auto',
    'audioDisplayScaling': 3000,

    'fpsSmoothing': 0.6, # this smoothes only the fps _debug display_, NOT the real fps

}


# setup window
cv2.namedWindow( options['windowName'], cv2.WINDOW_NORMAL )
cv2.resizeWindow( options['windowName'], options['screenWidth'], options['screenHeight'] )
cv2.setWindowProperty( options['windowName'], cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN )

# display startup image
startupImage = np.zeros((options['screenHeight'], options['screenWidth'], 3), np.uint8)
font = cv2.FONT_HERSHEY_TRIPLEX
text = 'loading ...'
fontSize = 1
fontWidth = 1
fontColor = (255,255,255)
textSize = cv2.getTextSize(text, font, fontSize, fontWidth)[0]
textX = int((options['screenWidth'] - textSize[0]) / 2)
textY = int((options['screenHeight'] - textSize[1]*2))
cv2.putText( img=startupImage, text=text, org=(textX, textY), fontFace=font, fontScale=fontSize, color=fontColor, thickness=fontWidth, lineType=cv2.LINE_AA )

cv2.imshow(options['windowName'], startupImage)
cv2.waitKey(60)

# get audio input options
pa = pyaudio.PyAudio()
if options['verbose']:
    print("listing microphones")
    for i in range(pa.get_device_count()):
        dev = pa.get_device_info_by_index(i)
        print(i,dev['name'],dev['maxInputChannels'])
        if options['audioDevice'] == 'auto' and dev['maxInputChannels'] > 0:
            options['audioDevice'] = i
            print('  automatically set audio device to '+str(i))
if pa.get_device_count() < options['audioDevice']:
    print('audio device index is out of range (found '+str(pa.get_device_count())+' audio devices, requested #'+str(options['audioDevice'])+')')
    sys.exit()
audioDevice = pa.get_device_info_by_index(options['audioDevice'])
if audioDevice['maxInputChannels'] <= 0:
    print('audio device has no input channels! aborting')
    print('(use "arecord -l" to check available devices)')
    sys.exit()
audioOptions = {
    'deviceIndex': audioDevice['index'],
    'sampleRate': int(audioDevice['defaultSampleRate']),
    'inputChannels': 1,
    'hopSize': options['bufferSize'],
    'winSize': options['bufferSize']*options['winSizeMultiple'],
}

if options['verbose']:
    print('')
    print('---------')
    print('')
    print('-- options --')
    print(options)
    print('')
    print('-- audio options --')
    print(audioOptions)
    print('')
    print('---------')
    print('')



class AudioProcessor():

    def __init__(self):

        self.fpsMeasurement = options['fps']
        self.previousTime = self.currentTime = time.time()
        self.fpsSmoothing = options['fpsSmoothing']

        self.beatQueue = Queue()
        self.pitchQueue = Queue()

        peakBufferSize = int(audioOptions['sampleRate']/options['bufferSize']) # one second worth of bufferSizes
        self.peakBuffer = np.zeros(peakBufferSize)
        self.peakBufferBeat = np.zeros(peakBufferSize)
        self.peakBufferIndex = 0

        volumeBufferSize = int((audioOptions['sampleRate']/options['bufferSize'])/options['fps']) # one frame worth of bufferSizes
        if volumeBufferSize < 1:
            volumeBufferSize = 1
        self.volumeBuffer = np.zeros(volumeBufferSize)
        self.volumeBufferIndex = 0

        self.tempoDetection = aubio.tempo(method='default', buf_size=audioOptions['winSize'], hop_size=audioOptions['hopSize'], samplerate=audioOptions['sampleRate'])

        self.pitchDetection = aubio.pitch(method='default', buf_size=audioOptions['winSize'], hop_size=audioOptions['hopSize'], samplerate=audioOptions['sampleRate'])
        self.pitchDetection.set_unit('cent')

        self.audio = pyaudio.PyAudio()
        self.stream = self.audio.open(format=pyaudio.paFloat32,
                    input=True,
                    channels=audioOptions['inputChannels'],
                    input_device_index=audioOptions['deviceIndex'],
                    frames_per_buffer=options['bufferSize'],
                    rate=audioOptions['sampleRate'],
                    stream_callback=self.readAudioFrames)


    def readAudioFrames(self, in_data, frame_count, time_info, status):

        signal = np.frombuffer(in_data, dtype=np.float32)

        volume = np.sum(signal**2)/len(signal)

        beat = self.tempoDetection(signal)
        if beat:
            bpm = self.tempoDetection.get_bpm()
            self.beatQueue.put(bpm)

        pitch = self.pitchDetection(signal)
        if pitch[0] != 0:
            self.pitchQueue.put(pitch[0])

        peak = np.abs(np.max(signal)-np.min(signal))
        self.peakBuffer[self.peakBufferIndex] = peak*options['audioDisplayScaling']
        self.peakBufferBeat[self.peakBufferIndex] = beat

        self.peakBufferIndex += 1
        if self.peakBufferIndex >= len(self.peakBuffer):
            self.peakBufferIndex = 0

        self.volumeBuffer[self.volumeBufferIndex] = volume

        self.volumeBufferIndex += 1
        if self.volumeBufferIndex >= len(self.volumeBuffer):
            self.volumeBufferIndex = 0

        self.previousTime, self.currentTime = self.currentTime, time.time()
        fps = math.ceil(1./(self.currentTime-self.previousTime))
        self.fpsMeasurement = (self.fpsMeasurement*self.fpsSmoothing) + (fps*(1.0-self.fpsSmoothing))

        return (in_data, pyaudio.paContinue)

    def getBeat(self):
        if self.beatQueue.qsize() > 0:
            return self.beatQueue.get()
        return False

    def getPitch(self):
        if self.pitchQueue.qsize() > 0:
            return self.pitchQueue.get()
        return False

    def getPeaks(self):
        return self.peakBuffer, self.peakBufferBeat, self.peakBufferIndex

    def getVolume(self):
        volume = np.sum(self.volumeBuffer)
        return volume

    def getFps(self):
        return self.fpsMeasurement

    def stop(self):
        self.stream.stop_stream()
        self.stream.close()
        self.audio.terminate()


targetTime = 1./options['fps']
frameNumber = 0
bpm = -1
framesPerInterval = -1
framesUntilNextBeat = -1
lateBeat = False
pitchValue = 0
oldPitchValue = 0

volumeBuffer = np.zeros(options['fps']*10) # 10 seconds worth of frames
volumeBufferIndex = 0
globalVolume = 0
globalAverageVolume = 0

fps = options['fps']
fpsDisplay = options['fps']
previousTime = time.time()
currentTime = time.time()

font = cv2.FONT_HERSHEY_TRIPLEX

audioProcessor = AudioProcessor()

# main loop
while True:

    startTime = time.time()

    framesUntilNextBeat -= 1
    if framesUntilNextBeat < 0:
        lateBeat = True
        framesUntilNextBeat = 0

    beat = audioProcessor.getBeat()
    if beat:
        bpm = beat
        beat = True
        framesPerInterval = framesUntilNextBeat = fps*60/bpm
        lateBeat = False

    if pitchValue > 0:
        oldPitchValue = pitchValue
    pitchValue = 0
    pitch = audioProcessor.getPitch()
    if pitch and pitch > 0:
        pitchValue = pitch

    globalVolume = audioProcessor.getVolume()
    volumeBuffer[volumeBufferIndex] = globalVolume
    volumeBufferIndex += 1
    if volumeBufferIndex >= len(volumeBuffer):
        volumeBufferIndex = 0
    globalAverageVolume = np.sum(volumeBuffer)/len(volumeBuffer)

    frame = np.zeros((options['screenHeight'], options['screenWidth'], 3), np.uint8)

    # frame count debug text
    text = 'frame #'+str(frameNumber)+' / next beat at #'+str(int(frameNumber+framesUntilNextBeat))
    fontSize = 1
    fontWidth = 1
    fontColor = (255,255,255)
    textSize = cv2.getTextSize(text, font, fontSize, fontWidth)[0]
    textX = 1
    textY = options['screenHeight']-1
    cv2.putText( img=frame, text=text, org=(textX, textY), fontFace=font, fontScale=fontSize, color=fontColor, thickness=fontWidth, lineType=cv2.LINE_AA )

    # fps debug text
    text = str(math.ceil(fpsDisplay))+' fps'
    fontSize = 1
    fontWidth = 1
    if fpsDisplay < options['fps']*0.8:
        fontColor = (0,0,255)
    elif fpsDisplay < options['fps']*0.9:
        fontColor = (0,255,255)
    else:
        fontColor = (0,255,0)
    textSize = cv2.getTextSize(text, font, fontSize, fontWidth)[0]
    textX = int((options['screenWidth'] - textSize[0]))
    textY = textSize[1]
    cv2.putText( img=frame, text=text, org=(textX, textY), fontFace=font, fontScale=fontSize, color=fontColor, thickness=fontWidth, lineType=cv2.LINE_AA )

    # audioProcessor fps debug text
    audioFps = audioProcessor.getFps()
    text = str(math.ceil(audioFps))+' audio fps'
    fontSize = 1
    fontWidth = 1
    fontColor = (255,255,255)
    textSize = cv2.getTextSize(text, font, fontSize, fontWidth)[0]
    textX = int((options['screenWidth'] - textSize[0]))
    textY += textSize[1] + 20
    cv2.putText( img=frame, text=text, org=(textX, textY), fontFace=font, fontScale=fontSize, color=fontColor, thickness=fontWidth, lineType=cv2.LINE_AA )

    # bpm debug text
    text = str(round(bpm))+' bpm'
    fontSize = 4
    fontWidth = 4
    fontColor = (255,255,255)
    if beat:
        fontColor = (0,0,255)
    textSize = cv2.getTextSize(text, font, fontSize, fontWidth)[0]
    textX = int((options['screenWidth'] - textSize[0])/2)
    textY = int(options['screenHeight']/3)
    cv2.putText( img=frame, text=text, org=(textX, textY), fontFace=font, fontScale=fontSize, color=fontColor, thickness=fontWidth, lineType=cv2.LINE_AA )

    # fpi debug text
    text = str(round(framesPerInterval))+' frames per interval'
    fontSize = 1
    fontWidth = 1
    fontColor = (255,255,255)
    if beat:
        fontColor = (0,0,255)
    textSize = cv2.getTextSize(text, font, fontSize, fontWidth)[0]
    textX = int((options['screenWidth'] - textSize[0])/2)
    textY += textSize[1]+50
    cv2.putText( img=frame, text=text, org=(textX, textY), fontFace=font, fontScale=fontSize, color=fontColor, thickness=fontWidth, lineType=cv2.LINE_AA )


    # print progress bar until next beat
    x = 300
    w = int(options['screenWidth'] - x*2)
    y = int(options['screenHeight'] * 2/3)
    h = 30
    c = (255,255,255)
    if lateBeat:
        c = (0,0,255)
    lineWidth = 1
    filledWidth = round((1-(framesUntilNextBeat/framesPerInterval))*w)
    cv2.rectangle( frame, (x,y), (x+w, y+h), c, lineWidth )
    cv2.rectangle( frame, (x,y), (x+filledWidth, y+h), c, -1 )
    text = 'next beat'
    fontSize = 1
    fontWidth = 1
    fontColor = (255,255,255)
    textSize = cv2.getTextSize(text, font, fontSize, fontWidth)[0]
    cv2.putText( img=frame, text=text, org=(x-textSize[0]-10, int(y+h/2+textSize[1]/2)), fontFace=font, fontScale=fontSize, color=fontColor, thickness=fontWidth, lineType=cv2.LINE_AA )

    # print pitch
    y += h + 20
    h = 30
    c = (255,255,255)
    cOld = (50,50,50)
    lineWidth = 1
    filledWidth = int((pitchValue)*w/100)
    filledWidthOld = int((oldPitchValue)*w/100)
    cv2.rectangle( frame, (x,y), (x+filledWidthOld, y+h), cOld, -1 )
    cv2.rectangle( frame, (x,y), (x+filledWidth, y+h), c, -1 )
    cv2.rectangle( frame, (x,y), (x+w, y+h), c, lineWidth )
    text = 'pitch'
    fontSize = 1
    fontWidth = 1
    fontColor = (255,255,255)
    textSize = cv2.getTextSize(text, font, fontSize, fontWidth)[0]
    cv2.putText( img=frame, text=text, org=(x-textSize[0]-10, int(y+h/2+textSize[1]/2)), fontFace=font, fontScale=fontSize, color=fontColor, thickness=fontWidth, lineType=cv2.LINE_AA )

    # print Volume
    y += h + 20
    h = 30
    c = (255,255,255)
    cB = (0,0,0)
    lineWidth = 1
    midW= int(w/2)
    scale = 4
    if globalAverageVolume > 0:
        volumePercent = globalVolume/globalAverageVolume
    else:
        volumePercent = 1
    if volumePercent > 2:
        volumePercent = 2
    filledWidth = midW*(volumePercent-1)
    cv2.rectangle( frame, (x+midW,y), (x+midW+int(filledWidth), y+h), c, -1 )
    cv2.rectangle( frame, (x,y), (x+w, y+h), c, lineWidth )
    text = 'volume'
    fontSize = 1
    fontWidth = 1
    fontColor = (255,255,255)
    textSize = cv2.getTextSize(text, font, fontSize, fontWidth)[0]
    cv2.putText( img=frame, text=text, org=(x-textSize[0]-10, int(y+h/2+textSize[1]/2)), fontFace=font, fontScale=fontSize, color=fontColor, thickness=fontWidth, lineType=cv2.LINE_AA )

    # print peaks
    data, beatData, index = audioProcessor.getPeaks()
    index -= 1
    if index < 0:
        index = options['fps']-1

    w = math.ceil(options['screenWidth']/len(data))
    x = options['screenWidth']-w
    y = int(options['screenHeight']*3/5)

    for i in range(len(data)):
        h = int(data[index])
        o = beatData[index]

        color = (255,255,255)
        if o:
            color = (0,0,255)

        cv2.rectangle( frame, (x,y), (x+w, y-h), color, -1 )

        x += w

        index += 1
        if index >= len(data):
            index = 0
        if x >= options['screenWidth']:
            x = 0



    cv2.imshow(options['windowName'], frame)

    frameNumber += 1

    previousTime, currentTime = currentTime, time.time()
    fps = round(1./(currentTime-previousTime))
    fpsDisplay = (fpsDisplay * options['fpsSmoothing']) + (fps * (1.0-options['fpsSmoothing']))


    usedTime = time.time() - startTime
    timeLeft = targetTime-usedTime
    sleepTime = int(timeLeft*1000)
    if sleepTime < 1:
        sleepTime = 1

    key = cv2.waitKey(sleepTime)

    if key == 27: # escape
        print('exiting')
        break



print('cleaning up ..')

audioProcessor.stop()
cv2.destroyAllWindows()

print('bye!')

